{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHy0EkHYutFY",
        "outputId": "fe3ab5df-c72a-4d9d-8c1d-0b28ef2606ea"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import io\n",
        "\n",
        "# Replace 'filename.zip' with the name of your zip file\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/archive (3).zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('extracted_contents')\n"
      ],
      "metadata": {
        "id": "3AGrqnBXvjIJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List the contents of the extracted folder\n",
        "extracted_files = os.listdir('extracted_contents')\n",
        "print(extracted_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZE35xVxvuUe",
        "outputId": "f9acf555-ccf1-4e7e-a779-c71e6119f21c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['test_v2', 'CSV', 'validation_v2', 'train_v2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.data as tfd\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "metadata": {
        "id": "L91MYaCDvx8l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as implt\n",
        "from IPython.display import clear_output as cls"
      ],
      "metadata": {
        "id": "xDphqutswWfR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_WIDTH = 200\n",
        "IMG_HEIGHT = 50\n",
        "IMG_SIZE = (IMG_WIDTH, IMG_HEIGHT)\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 150\n",
        "LEARNING_RATE = 1e-3\n",
        "MODEL_NAME = \"CharacterRecognition-Model\"\n",
        "TRAIN_SIZE = BATCH_SIZE * 3000\n",
        "VALID_SIZE = BATCH_SIZE * 1500\n",
        "TEST_SIZE  = BATCH_SIZE * 300\n",
        "AUTOTUNE = tfd.AUTOTUNE\n",
        "\n",
        "# Training callbacks\n",
        "CALLBACKS = [\n",
        "    EarlyStopping(patience=10, restore_best_weights=True),\n",
        "    ModelCheckpoint(filepath=MODEL_NAME + \".h5\", save_best_only=True)\n",
        "]\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the zipped file in your Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/archive (3).zip'\n",
        "\n",
        "# Directory to extract the contents of the zip file\n",
        "extracted_dir = '/content/extracted_data'\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "import zipfile\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_dir)\n",
        "\n",
        "# Updated Paths\n",
        "train_csv_path = os.path.join(extracted_dir, 'CSV', 'written_name_train.csv')\n",
        "valid_csv_path = os.path.join(extracted_dir, 'CSV', 'written_name_validation.csv')\n",
        "test_csv_path = os.path.join(extracted_dir, 'CSV', 'written_name_test.csv')\n",
        "train_image_dir = os.path.join(extracted_dir, 'train_v2', 'train')\n",
        "valid_image_dir = os.path.join(extracted_dir, 'validation_v2', 'validation')\n",
        "test_image_dir = os.path.join(extracted_dir, 'test_v2', 'test')\n",
        "\n",
        "\n",
        "# SetUp random seeds for numpy and TensorFlow\n",
        "np.random.seed(2569)\n",
        "tf.random.set_seed(2569)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNaSlJ6Uwc6r",
        "outputId": "b8c84b03-866f-47e2-887b-e9fdcfdf9e37"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the csv files\n",
        "train_csv = pd.read_csv(train_csv_path)[:TRAIN_SIZE]\n",
        "test_csv = pd.read_csv(test_csv_path)[:TEST_SIZE]\n",
        "valid_csv = pd.read_csv(valid_csv_path)[:VALID_SIZE]"
      ],
      "metadata": {
        "id": "_Vs3QIG6xms2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the train labels\n",
        "train_labels = [str(word) for word in train_csv[\"IDENTITY\"].to_numpy()]\n",
        "\n",
        "# extract all the unique characters\n",
        "unique_characters = set(char for word in train_labels for char in word)\n",
        "# define the number of classes (for labels) based on the number of unique characters\n",
        "n_classes = len(unique_characters)\n",
        "\n",
        "# get the maximum length that a label can have\n",
        "MAX_LABEL_LENGTH = max(map(len, train_labels))"
      ],
      "metadata": {
        "id": "HyJn5R65xsI_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Char to Num\n",
        "char_to_num = StringLookup(vocabulary=list(unique_characters), mask_token=None)\n",
        "num_to_char = StringLookup(vocabulary = char_to_num.get_vocabulary(), mask_token = None, invert = True)"
      ],
      "metadata": {
        "id": "l6fl5SabxvaA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(image_path):\n",
        "    \"\"\"\n",
        "    This function gets the image path and\n",
        "    reads the image usin TensorFlow, Then the image will be decoded and\n",
        "    will be converted to float data type. next resize and transpose will be applied to it.\n",
        "    In the final step the image will be converted to a Numpy Array using tf.cast\n",
        "    \"\"\"\n",
        "    # read the image\n",
        "    image = tf.io.read_file('/content/drive/MyDrive/testimage.jpeg')\n",
        "    # decode the image\n",
        "    decoded_image = tf.image.decode_jpeg(contents=image, channels=1)\n",
        "    # convert image data type to float32\n",
        "    convert_imgs = tf.image.convert_image_dtype(image=decoded_image, dtype=tf.float32)\n",
        "    # resize and transpose\n",
        "    resized_image = tf.image.resize(images=convert_imgs, size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "    image = tf.transpose(resized_image, perm = [1, 0, 2])\n",
        "\n",
        "    # to numpy array (Tensor)\n",
        "    image_array = tf.cast(image, dtype=tf.float32)\n",
        "\n",
        "    return image_array"
      ],
      "metadata": {
        "id": "IrjCpOklx0-1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_single_sample(image_path, label:str):\n",
        "\n",
        "    '''\n",
        "    The function takes an image path and label as input and returns a dictionary containing the processed image tensor and the label tensor.\n",
        "    First, it loads the image using the load_image function, which decodes and resizes the image to a specific size. Then it converts the given\n",
        "    label string into a sequence of Unicode characters using the unicode_split function. Next, it uses the char_to_num layer to convert each\n",
        "    character in the label to a numerical representation. It pads the numerical representation with a special class (n_classes)\n",
        "    to ensure that all labels have the same length (MAX_LABEL_LENGTH). Finally, it returns a dictionary containing the processed image tensor\n",
        "    and the label tensor.\n",
        "\n",
        "    '''\n",
        "\n",
        "    # Get the image\n",
        "    image = load_image('/content/drive/MyDrive/testimage.jpeg')\n",
        "    # Convert the label into characters\n",
        "    chars = tf.strings.unicode_split(label, input_encoding='UTF-8')\n",
        "    # Convert the characters into vectors\n",
        "    vecs = char_to_num(chars)\n",
        "\n",
        "    # Pad label\n",
        "    pad_size = MAX_LABEL_LENGTH - tf.shape(vecs)[0]\n",
        "    vecs = tf.pad(vecs, paddings = [[0, pad_size]], constant_values=n_classes+1)\n",
        "\n",
        "    return {'image':image, 'label':vecs}"
      ],
      "metadata": {
        "id": "bkooEVNHx2du"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Assuming AUTOTUNE, BATCH_SIZE, and encode_single_sample are defined elsewhere\n",
        "\n",
        "# Training Data\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (np.array(train_csv['FILENAME'].to_list()), np.array(train_csv['IDENTITY'].to_list()))\n",
        ").shuffle(1000).map(encode_single_sample, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "# Validation data\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (np.array(valid_csv['FILENAME'].to_list()), np.array(valid_csv['IDENTITY'].to_list()))\n",
        ").map(encode_single_sample, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "# Testing data.\n",
        "test_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (np.array(test_csv['FILENAME'].to_list()), np.array(test_csv['IDENTITY'].to_list()))\n",
        ").map(encode_single_sample, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "print(train_ds)\n",
        "print(valid_ds)\n",
        "print(test_ds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "n5J5SSVFx7d6",
        "outputId": "a53847a0-1d17-4464-8e93-30c8764a65f2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_csv' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f443090b6812>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Training Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m train_ds = tf.data.Dataset.from_tensor_slices(\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_csv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FILENAME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_csv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IDENTITY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m ).shuffle(1000).map(encode_single_sample, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_csv' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(data, GRID=[4,4], FIGSIZE=(25, 8), cmap='binary_r', model=None, decode_pred=None):\n",
        "\n",
        "    # Plotting configurations\n",
        "    plt.figure(figsize=FIGSIZE)\n",
        "    n_rows, n_cols = GRID\n",
        "\n",
        "    # Loading Data\n",
        "    data = next(iter(data))\n",
        "    images, labels = data['image'], data['label']\n",
        "\n",
        "    # Iterate over the data\n",
        "    for index, (image, label) in enumerate(zip(images, labels)):\n",
        "\n",
        "        # Label processing\n",
        "        text_label = num_to_char(label)\n",
        "        text_label = tf.strings.reduce_join(text_label).numpy().decode('UTF-8')\n",
        "        text_label = text_label.replace(\"[UNK]\", \" \").strip()\n",
        "\n",
        "        # Create a sub plot\n",
        "        plt.subplot(n_rows, n_cols, index+1)\n",
        "        plt.imshow(tf.transpose(image, perm=[1,0,2]), cmap=cmap)\n",
        "        plt.axis('off')\n",
        "\n",
        "        if model is not None and decode_pred is not None:\n",
        "            # Make prediction\n",
        "            pred = model.predict(tf.expand_dims(image, axis=0))\n",
        "            pred = decode_pred(pred)[0]\n",
        "            title = f\"True : {text_label}\\nPred : {pred}\"\n",
        "            plt.title(title)\n",
        "        else:\n",
        "            # add title\n",
        "            plt.title(text_label)\n",
        "\n",
        "    # Show the final plot\n",
        "    cls()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "gNY79rDUyd98"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CTCLayer(Layer):\n",
        "    def __init__(self, **kwargs) -> None:\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # define the loss function\n",
        "        self.loss_function = tf.keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_hat):\n",
        "        # Get the batch length\n",
        "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "\n",
        "        # get the input and label lengths\n",
        "        input_len = tf.cast(tf.shape(y_hat)[1], dtype='int64') * tf.ones(shape=(batch_len, 1), dtype='int64')\n",
        "        label_len = tf.cast(tf.shape(y_true)[1], dtype='int64') * tf.ones(shape=(batch_len, 1), dtype='int64')\n",
        "\n",
        "        # calculate the loss\n",
        "        loss = self.loss_function(y_true, y_hat, input_len, label_len)\n",
        "\n",
        "        self.add_loss(loss)\n",
        "\n",
        "        return y_hat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "pa97NwHbyAas",
        "outputId": "d45d5907-c563-42b2-ad15-93bfa12c5789"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Layer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-f2d30b1068b6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCTCLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# define the loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Layer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input Layer\n",
        "input_images = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 1), name=\"image\")\n",
        "\n",
        "# Labels : These are added for the training purpose.\n",
        "input_labels = Input(shape=(None, ), name=\"label\")\n",
        "\n",
        "### Convolutional layers\n",
        "# layer 1\n",
        "conv_1 = Conv2D(64, 3, strides=1, padding=\"same\", kernel_initializer=\"he_normal\", activation=\"relu\", name=\"conv_1\")(input_images)\n",
        "# layer 2\n",
        "conv_2 = Conv2D(32, 3, strides=1, padding=\"same\", kernel_initializer=\"he_normal\", activation=\"relu\", name=\"conv_2\")(conv_1)\n",
        "max_pool_1 = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(conv_2)\n",
        "# layer 3\n",
        "conv_3 = Conv2D(64, 3, strides=1, padding='same', activation='relu', kernel_initializer='he_normal', name=\"conv_3\")(max_pool_1)\n",
        "conv_4 = Conv2D(32, 3, strides=1, padding='same', activation='relu', kernel_initializer='he_normal', name=\"conv_4\")(conv_3)\n",
        "max_pool_2 = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(conv_4)\n",
        "\n",
        "\n",
        "\n",
        "### Encoding\n",
        "reshape = Reshape(target_shape=((IMG_WIDTH//4), (IMG_HEIGHT//4)*32), name=\"reshape_layer\")(max_pool_2)\n",
        "dense_encoding = Dense(64, kernel_initializer=\"he_normal\", activation=\"relu\", name=\"enconding_dense\")(reshape)\n",
        "dense_encoding_2 = Dense(64, kernel_initializer=\"he_normal\", activation=\"relu\", name=\"enconding_dense_2\")(dense_encoding)\n",
        "dropout = Dropout(0.4)(dense_encoding_2)\n",
        "\n",
        "# Decoder\n",
        "lstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout=0.25), name=\"bidirectional_lstm_1\")(dropout)\n",
        "lstm_2 = Bidirectional(LSTM(64, return_sequences=True, dropout=0.25), name=\"bidirectional_lstm_2\")(lstm_1)\n",
        "\n",
        "# Final Output layer\n",
        "output = Dense(len(char_to_num.get_vocabulary())+1, activation=\"softmax\", name=\"output_dense\")(lstm_2)\n",
        "\n",
        "# Add the CTC loss\n",
        "ctc_loss_layer = CTCLayer()(input_labels, output)\n",
        "\n",
        "# Define the final model\n",
        "model = Model(inputs=[input_images, input_labels], outputs=[ctc_loss_layer])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "csH0Togyyvrb",
        "outputId": "daab7e4e-fe0c-4b68-f4ae-49d8eb36e065"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Input' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ef09449fe397>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Input Layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_WIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_HEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Labels : These are added for the training purpose.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_prediction(pred_label):\n",
        "    \"\"\"\n",
        "    This function has the job to decode the prediction that the model had.\n",
        "    The model predicts each character and then this function makes it readable.\n",
        "    \"\"\"\n",
        "    # Input length\n",
        "    input_len = np.ones(shape=pred_label.shape[0]) * pred_label.shape[1]\n",
        "\n",
        "    # CTC decode\n",
        "    decode = tf.keras.backend.ctc_decode(pred_label, input_length=input_len, greedy=True)[0][0][:,:MAX_LABEL_LENGTH]\n",
        "\n",
        "    # Converting numerics back to their character values\n",
        "    chars = num_to_char(decode)\n",
        "\n",
        "    # Join all the characters\n",
        "    texts = [tf.strings.reduce_join(inputs=char).numpy().decode('UTF-8') for char in chars]\n",
        "\n",
        "    # Remove the unknown token\n",
        "    filtered_texts = [text.replace('[UNK]', \" \").strip() for text in texts]\n",
        "\n",
        "    return filtered_texts"
      ],
      "metadata": {
        "id": "ygu8HtDVy9F8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def single_sample_prediction(model, path):\n",
        "    \"\"\"\n",
        "    This function gets an image path and the model,\n",
        "    Loads and preprocesses the image and make predictions on it.\n",
        "    \"\"\"\n",
        "    # load image\n",
        "    image_loading = tf.io.read_file('/content/drive/MyDrive/testimage.jpeg')\n",
        "    # decode image\n",
        "    decoded_image = tf.image.decode_jpeg(contents=image_loading, channels=1)\n",
        "    # convert the image data type to float\n",
        "    convert_image = tf.image.convert_image_dtype(image=decoded_image, dtype=tf.float32)\n",
        "    # resize the image\n",
        "    resized_image = tf.image.resize(images=convert_image, size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "    resized_image = tf.transpose(resized_image, perm = [1, 0, 2])\n",
        "    # convert image to array\n",
        "    image_array = tf.cast(resized_image, dtype=tf.float32)\n",
        "    # reshape image\n",
        "    single_image_data_with_batch = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "    # make prediction\n",
        "    prediction = decoder_prediction(model.predict(single_image_data_with_batch))\n",
        "\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "fI7gEqm5zL21"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}